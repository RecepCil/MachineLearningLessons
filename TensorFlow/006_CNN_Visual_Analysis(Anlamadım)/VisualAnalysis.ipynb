{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"LXo8LbSCGcWO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":5654},"outputId":"a619db37-f0dc-415f-cd15-bbf548ed91e8"},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","\n","#from google.colab import files\n","#src = list(files.upload().values())[0]    # add a new lib from computer\n","#open('mylib.py','wb').write(src)\n","#import mylib\n","\n","import inception\n","inception.download()\n","\n","# conv katmanların ismini alıcak bir fonk\n","def conv_layer_names():\n","  model = inception.Inception()\n","  names = [op.name for op in model.graph.get_operations() if op.type == 'Conv2D']\n","  model.close()\n","  return names\n","\n","# Şimdi bu isimleri bir listeye atayalım\n","conv_names = conv_layer_names()\n","\n","# gradient ascent uygulayacağımız fonk\n","def optimize_image(conv_id=0, feature=0, iterations=30, show_progress=30):\n","  model = inception.Inception()\n","  resized_image = model.resized_image\n","  \n","# parametre ile gelen conv_id'ye göre conv alıp tensorünü alıyoruz\n","  conv_name = conv_names[conv_id]\n","  tensor = model.graph.get_tensor_by_name(conv_name + \":0\")\n","  \n","# operatör ekleyebilmek için inception modelinin grafiğini default yapıyoruz\n","  with model.graph.as_default():\n","#loss fonksiyonu belirtilen feature için bütün tensor değerlerinin ortalaması\n","# o feature için loss değerini alalım\n","    loss = tf.reduce_mean(tensor[:, :, :, feature])\n","    \n","#resized image'a göre loss fonksiyonu için gradient alıcaz\n","#bunu tf.gradients ile yapıyoruz\n","  gradient = tf.gradients(loss, resized_image)\n","  \n","# Grafiği çalıştırmak için tf session açıyoruz  \n","  sess = tf.Session(graph=model.graph)\n","  \n","# rastgele resized_image boyutunda bir resim üretiyoruz(önce boyut alalım)\n","  image_shape = resized_image.get_shape()\n","  \n","# buna rastgele değerler atıyoruz np.random.uniform ile\n","# bu 128 değeri bize resim etrafında rastgele renkler vericek\n","# farklı değerler de atayabilirsin, bu şekilde görmesi daha kolay olucak\n","  image = np.random.uniform(size=image_shape) +  128.0\n","  \n","# optimizasyon \n","  for i in range(iterations):\n","    feed_dict = {model.tensor_name_resized_image: image}\n","    [grad, loss_value] = sess.run([gradient, loss], feed_dict=feed_dict)\n","\n","# gradient'i np.array'e sıkıştırıyoruz\n","# gradient artık bize, input resmini ne kadar değiştirirsek \n","# feature'u maksimize ederizi gösteriyor\n","    grad = np.array(grad).squeeze()\n","    \n","# step size ile adım büyüklüğünü hesaplayacağız\n","# 1e-8 ile sıfırla bölünmesini engelliyoruz\n","# learning rate ile aynı şey aslında ama burda farklı bir şekilde kullanıyoruz\n","    step_size = 1.0 / (grad.std() + 1e-8)\n","# gradient ascent \n","    image += step_size * grad\n","# np.clip ile resmin 0 ile 255 arasında olduğundan emin oluyoruz\n","    image = np.clip(image, 0.0, 255.0)\n","    \n","    if show_progress:\n","      print(\"Iteration: \", i)\n","      msg = \"Gradient min: {0:9.6f}, max: {1:>9.6f}, stepsize: {2:>9.2f}\"\n","      print(msg.format(grad.min(), grad.max(), step_size))\n","      print(\"Loss: \", loss_value)\n","      print()\n","      \n","  model.close()\n","  return image.squeeze()\n","\n","# resmi normalleştiriyoruz(resmin değerlerini 0 ile 1 arasına sıkıştırıyoruz)\n","def normalize_image(x):\n","  x_min = x.min()\n","  x_max = x.max()\n","   \n","  x_norm = (x-x_min)/(x_max-x_min)\n","    \n","  return x_norm\n","\n","# resimleri yazdıracak fonksiyonu yazalım\n","def plot_image(image):\n","  img_norm = normalize_image(image) #önce resmi normalleştiriyoruz\n","  plt.imshow(img_norm)\n","  plt.show()\n","  \n","# artık optimizeye başlayabiliriz\n","\n","image = optimize_image(conv_id=10, feature=50, iterations=130)\n","\n","plot_image(image)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Data already exists.\n","Iteration:  0\n","Gradient min: -0.000127, max:  0.000122, stepsize:  90423.76\n","Loss:  -1.8251309\n","\n","Iteration:  1\n","Gradient min: -0.000052, max:  0.000064, stepsize: 231189.21\n","Loss:  -2.4000976\n","\n","Iteration:  2\n","Gradient min: -0.000048, max:  0.000039, stepsize: 264003.32\n","Loss:  -2.3616502\n","\n","Iteration:  3\n","Gradient min: -0.000045, max:  0.000046, stepsize: 270776.18\n","Loss:  -2.3103664\n","\n","Iteration:  4\n","Gradient min: -0.000033, max:  0.000040, stepsize: 286408.96\n","Loss:  -2.245346\n","\n","Iteration:  5\n","Gradient min: -0.000035, max:  0.000031, stepsize: 300172.23\n","Loss:  -2.1955256\n","\n","Iteration:  6\n","Gradient min: -0.000036, max:  0.000047, stepsize: 310793.77\n","Loss:  -2.1389198\n","\n","Iteration:  7\n","Gradient min: -0.000038, max:  0.000037, stepsize: 325209.35\n","Loss:  -2.0911376\n","\n","Iteration:  8\n","Gradient min: -0.000038, max:  0.000039, stepsize: 322949.42\n","Loss:  -2.0499415\n","\n","Iteration:  9\n","Gradient min: -0.000033, max:  0.000032, stepsize: 349654.51\n","Loss:  -2.01014\n","\n","Iteration:  10\n","Gradient min: -0.000031, max:  0.000035, stepsize: 361678.26\n","Loss:  -1.9699879\n","\n","Iteration:  11\n","Gradient min: -0.000031, max:  0.000036, stepsize: 378090.96\n","Loss:  -1.9425507\n","\n","Iteration:  12\n","Gradient min: -0.000030, max:  0.000033, stepsize: 394702.49\n","Loss:  -1.9186475\n","\n","Iteration:  13\n","Gradient min: -0.000039, max:  0.000034, stepsize: 410996.72\n","Loss:  -1.8879124\n","\n","Iteration:  14\n","Gradient min: -0.000031, max:  0.000035, stepsize: 437255.69\n","Loss:  -1.8653587\n","\n","Iteration:  15\n","Gradient min: -0.000025, max:  0.000025, stepsize: 448564.74\n","Loss:  -1.8391037\n","\n","Iteration:  16\n","Gradient min: -0.000030, max:  0.000028, stepsize: 458368.75\n","Loss:  -1.8227786\n","\n","Iteration:  17\n","Gradient min: -0.000030, max:  0.000049, stepsize: 457808.36\n","Loss:  -1.805497\n","\n","Iteration:  18\n","Gradient min: -0.000026, max:  0.000022, stepsize: 483524.05\n","Loss:  -1.7848358\n","\n","Iteration:  19\n","Gradient min: -0.000030, max:  0.000029, stepsize: 486721.41\n","Loss:  -1.7710762\n","\n","Iteration:  20\n","Gradient min: -0.000024, max:  0.000033, stepsize: 497777.94\n","Loss:  -1.7539374\n","\n","Iteration:  21\n","Gradient min: -0.000030, max:  0.000024, stepsize: 505170.04\n","Loss:  -1.7382376\n","\n","Iteration:  22\n","Gradient min: -0.000023, max:  0.000028, stepsize: 503303.80\n","Loss:  -1.7253276\n","\n","Iteration:  23\n","Gradient min: -0.000036, max:  0.000028, stepsize: 523232.51\n","Loss:  -1.7106106\n","\n","Iteration:  24\n","Gradient min: -0.000026, max:  0.000031, stepsize: 539030.16\n","Loss:  -1.6956866\n","\n","Iteration:  25\n","Gradient min: -0.000022, max:  0.000027, stepsize: 537305.24\n","Loss:  -1.687629\n","\n","Iteration:  26\n","Gradient min: -0.000020, max:  0.000026, stepsize: 544676.60\n","Loss:  -1.6696532\n","\n","Iteration:  27\n","Gradient min: -0.000031, max:  0.000030, stepsize: 551829.04\n","Loss:  -1.6616375\n","\n","Iteration:  28\n","Gradient min: -0.000030, max:  0.000037, stepsize: 557576.10\n","Loss:  -1.6439779\n","\n","Iteration:  29\n","Gradient min: -0.000032, max:  0.000027, stepsize: 553049.68\n","Loss:  -1.6348151\n","\n","Iteration:  30\n","Gradient min: -0.000029, max:  0.000026, stepsize: 561177.32\n","Loss:  -1.6232891\n","\n","Iteration:  31\n","Gradient min: -0.000025, max:  0.000022, stepsize: 578845.71\n","Loss:  -1.6087892\n","\n","Iteration:  32\n","Gradient min: -0.000029, max:  0.000026, stepsize: 582506.63\n","Loss:  -1.6003698\n","\n","Iteration:  33\n","Gradient min: -0.000027, max:  0.000024, stepsize: 585532.08\n","Loss:  -1.587334\n","\n","Iteration:  34\n","Gradient min: -0.000033, max:  0.000023, stepsize: 579770.12\n","Loss:  -1.5771422\n","\n","Iteration:  35\n","Gradient min: -0.000026, max:  0.000026, stepsize: 584029.83\n","Loss:  -1.5590906\n","\n","Iteration:  36\n","Gradient min: -0.000023, max:  0.000024, stepsize: 577825.91\n","Loss:  -1.5544386\n","\n","Iteration:  37\n","Gradient min: -0.000023, max:  0.000022, stepsize: 594487.95\n","Loss:  -1.535516\n","\n","Iteration:  38\n","Gradient min: -0.000025, max:  0.000023, stepsize: 586552.80\n","Loss:  -1.5207249\n","\n","Iteration:  39\n","Gradient min: -0.000028, max:  0.000027, stepsize: 577668.96\n","Loss:  -1.5089839\n","\n","Iteration:  40\n","Gradient min: -0.000028, max:  0.000033, stepsize: 580906.64\n","Loss:  -1.4902886\n","\n","Iteration:  41\n","Gradient min: -0.000022, max:  0.000030, stepsize: 588809.33\n","Loss:  -1.4719571\n","\n","Iteration:  42\n","Gradient min: -0.000031, max:  0.000032, stepsize: 573497.35\n","Loss:  -1.4562124\n","\n","Iteration:  43\n","Gradient min: -0.000030, max:  0.000024, stepsize: 581999.07\n","Loss:  -1.4377522\n","\n","Iteration:  44\n","Gradient min: -0.000023, max:  0.000032, stepsize: 574673.85\n","Loss:  -1.4226459\n","\n","Iteration:  45\n","Gradient min: -0.000032, max:  0.000028, stepsize: 584689.05\n","Loss:  -1.4003582\n","\n","Iteration:  46\n","Gradient min: -0.000028, max:  0.000032, stepsize: 574751.92\n","Loss:  -1.3849832\n","\n","Iteration:  47\n","Gradient min: -0.000026, max:  0.000028, stepsize: 584150.88\n","Loss:  -1.3642066\n","\n","Iteration:  48\n","Gradient min: -0.000025, max:  0.000030, stepsize: 574040.64\n","Loss:  -1.3509562\n","\n","Iteration:  49\n","Gradient min: -0.000026, max:  0.000023, stepsize: 589166.80\n","Loss:  -1.328828\n","\n","Iteration:  50\n","Gradient min: -0.000027, max:  0.000024, stepsize: 581532.57\n","Loss:  -1.3100054\n","\n","Iteration:  51\n","Gradient min: -0.000032, max:  0.000024, stepsize: 588639.07\n","Loss:  -1.2959673\n","\n","Iteration:  52\n","Gradient min: -0.000028, max:  0.000031, stepsize: 600245.18\n","Loss:  -1.2762371\n","\n","Iteration:  53\n","Gradient min: -0.000026, max:  0.000026, stepsize: 607987.24\n","Loss:  -1.2611247\n","\n","Iteration:  54\n","Gradient min: -0.000034, max:  0.000025, stepsize: 615230.75\n","Loss:  -1.2419146\n","\n","Iteration:  55\n","Gradient min: -0.000023, max:  0.000042, stepsize: 609236.07\n","Loss:  -1.2310344\n","\n","Iteration:  56\n","Gradient min: -0.000023, max:  0.000022, stepsize: 627342.30\n","Loss:  -1.2122327\n","\n","Iteration:  57\n","Gradient min: -0.000024, max:  0.000021, stepsize: 639653.15\n","Loss:  -1.1977383\n","\n","Iteration:  58\n","Gradient min: -0.000031, max:  0.000027, stepsize: 631545.32\n","Loss:  -1.1823908\n","\n","Iteration:  59\n","Gradient min: -0.000026, max:  0.000024, stepsize: 649366.44\n","Loss:  -1.1661422\n","\n","Iteration:  60\n","Gradient min: -0.000022, max:  0.000022, stepsize: 654594.00\n","Loss:  -1.1539661\n","\n","Iteration:  61\n","Gradient min: -0.000034, max:  0.000025, stepsize: 645549.51\n","Loss:  -1.1415682\n","\n","Iteration:  62\n","Gradient min: -0.000023, max:  0.000025, stepsize: 673200.15\n","Loss:  -1.1253264\n","\n","Iteration:  63\n","Gradient min: -0.000023, max:  0.000022, stepsize: 669235.42\n","Loss:  -1.1132475\n","\n","Iteration:  64\n","Gradient min: -0.000022, max:  0.000022, stepsize: 676697.71\n","Loss:  -1.1008356\n","\n","Iteration:  65\n","Gradient min: -0.000029, max:  0.000021, stepsize: 684063.90\n","Loss:  -1.0871884\n","\n","Iteration:  66\n","Gradient min: -0.000034, max:  0.000033, stepsize: 696734.26\n","Loss:  -1.0720797\n","\n","Iteration:  67\n","Gradient min: -0.000036, max:  0.000030, stepsize: 691688.15\n","Loss:  -1.0643884\n","\n","Iteration:  68\n","Gradient min: -0.000029, max:  0.000039, stepsize: 695923.94\n","Loss:  -1.0502666\n","\n","Iteration:  69\n","Gradient min: -0.000024, max:  0.000026, stepsize: 705257.52\n","Loss:  -1.0387009\n","\n","Iteration:  70\n","Gradient min: -0.000025, max:  0.000021, stepsize: 713686.59\n","Loss:  -1.0264592\n","\n","Iteration:  71\n","Gradient min: -0.000025, max:  0.000028, stepsize: 719775.40\n","Loss:  -1.0148977\n","\n","Iteration:  72\n","Gradient min: -0.000021, max:  0.000022, stepsize: 735706.76\n","Loss:  -1.0029702\n","\n","Iteration:  73\n","Gradient min: -0.000020, max:  0.000018, stepsize: 728291.16\n","Loss:  -0.9932167\n","\n","Iteration:  74\n","Gradient min: -0.000027, max:  0.000022, stepsize: 726563.02\n","Loss:  -0.9831272\n","\n","Iteration:  75\n","Gradient min: -0.000024, max:  0.000023, stepsize: 740205.70\n","Loss:  -0.97052747\n","\n","Iteration:  76\n","Gradient min: -0.000026, max:  0.000030, stepsize: 731798.82\n","Loss:  -0.96001637\n","\n","Iteration:  77\n","Gradient min: -0.000030, max:  0.000026, stepsize: 755673.23\n","Loss:  -0.9493015\n","\n","Iteration:  78\n","Gradient min: -0.000032, max:  0.000031, stepsize: 751567.46\n","Loss:  -0.9395635\n","\n","Iteration:  79\n","Gradient min: -0.000030, max:  0.000023, stepsize: 758312.13\n","Loss:  -0.9299552\n","\n","Iteration:  80\n","Gradient min: -0.000021, max:  0.000026, stepsize: 755328.08\n","Loss:  -0.91882735\n","\n","Iteration:  81\n","Gradient min: -0.000023, max:  0.000022, stepsize: 763446.36\n","Loss:  -0.9106017\n","\n","Iteration:  82\n","Gradient min: -0.000024, max:  0.000028, stepsize: 770808.12\n","Loss:  -0.9006896\n","\n","Iteration:  83\n","Gradient min: -0.000024, max:  0.000023, stepsize: 780985.17\n","Loss:  -0.88874245\n","\n","Iteration:  84\n","Gradient min: -0.000027, max:  0.000022, stepsize: 784157.22\n","Loss:  -0.8800464\n","\n","Iteration:  85\n","Gradient min: -0.000019, max:  0.000018, stepsize: 797854.37\n","Loss:  -0.8708182\n","\n","Iteration:  "],"name":"stdout"}]}]}